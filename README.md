# TACT: A Table-Centric Approach for Accurate and Efficient Table Union Search

This repository contains the official implementation of **TACT**, a table-centric approach for accurate and efficient table union search. 

**TACT** treats entire tables as first-class entities and learns unionability-aware table embeddings through table-level contrastive learning. **TACT** captures robust and discriminative table semantics through an attentive table encoder equipped with tailored serialization, which learns from positives generated by stochastic row and column sub-sampling, and a two-pronged negative sampling strategy combining latent positive exclusion with hard negative mining. At query time, **TACT** performs fast and table-centric adaptive candidate retrieval, followed by a lightweight dual-evidence reranking that integrates table-level similarity with column alignment.


## ‚öôÔ∏è Requirements

All dependencies required to run **TACT** can be installed with the following command:

```bash
pip install -r requirements.txt
```


## üìä Datasets

The following table summarizes the benchmarks used in our experiments and provides their download links.

| **Dataset**    | **Link**                                                                                                                   |
| -------------- | -------------------------------------------------------------------------------------------------------------------------- |
| **SANTOS**     | [https://zenodo.org/record/7758091](https://zenodo.org/record/7758091)                                                     |
| **TUS**        | [https://github.com/RJMillerLab/table-union-search-benchmark](https://github.com/RJMillerLab/table-union-search-benchmark) |
| **Wiki Union** | [./data](./data)                                                                                                           |
| **WDC**        | [https://webdatacommons.org/webtables/](https://webdatacommons.org/webtables/)                                             |

For the **SANTOS**, **TUS**, and **WDC** benchmarks, we include links to their official sources.
For the **Wiki Union** benchmark, which we constructed based on existing resources, we provide our version of the dataset in this repository to facilitate future research.
We also thank [**LakeBench**](https://zenodo.org/records/8014643) for providing the data and labels that served as the foundation for constructing the **Wiki Union** benchmark.


## üöÄ Run the Code

This section provides instructions for running **TACT**, including pretraining, inference, querying, and reranking.

1. Pretrain by running:

    ```bash
    python pretrain.py --task [task] --logdir [dir_path] --save_model
    ```

    where
    * `task`: Name of the dataset (e.g., `santos`, `santosLarge`, `tus`, `tusLarge`, `wiki`, `wdc`)
    * `logdir`: Directory path for saving models
    * `save_model`: Optional flag to save the model

    i.e.,
    ```bash
    python pretrain.py --task santos --logdir ./Models --save_model
    ```

2. Inference by running:

    ```bash
    python extractTACT.py --benchmark [task] --save_model & python extractFasttext.py --task [task] & wait
    ```

    i.e.,
    ```bash
    python extractTACT.py --benchmark santos --save_model & python extractFasttext.py --task santos & wait
    ```

3. Query by running 

    ```bash
    python query.py --benchmark [task] --K [top_k_value]
    ```

    where
    * `top_k_value`: Number of retrieved candidates, reflecting the typical number of unionable tables per query
    - *K = 60* for **TUS** datasets
    - *K = 10* for **SANTOS** and **WDC** datasets
    - *K = 40* for **Wiki Union**.

    i.e.,
    ```bash
    python query.py --benchmark santos --K 10
    ```

4. Reranking by running

    ```bash
    python rerank.py --task [task]
    ```

    i.e.,
    ```bash
    python rerank.py --task santos
    ```

## üôè Acknowledgement

We gratefully acknowledge the open-source implementation of [**Starmie**](https://github.com/megagonlabs/starmie), which provides basic components that facilitated parts of our implementation.
We also thank [**LakeBench**](https://zenodo.org/records/8014643) for providing the data and labels that served as the foundation for constructing the **Wiki Union** benchmark.