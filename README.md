# TACT: A Table-Centric Approach for Accurate and Efficient Table Union Search

This repository contains the official implementation of **TACT**, a table-centric approach for accurate and efficient table union search. 

**TACT** treats entire tables as first-class entities and learns unionability-aware table embeddings through table-level contrastive learning. **TACT** captures robust and discriminative table semantics through an attentive table encoder equipped with tailored serialization, which learns from positives generated by stochastic row and column sub-sampling, and a two-pronged negative sampling strategy combining latent positive exclusion with hard negative mining. At query time, **TACT** performs fast and table-centric adaptive candidate retrieval, followed by a lightweight dual-evidence reranking that integrates table-level similarity with column alignment.


## ‚öôÔ∏è Requirements

All dependencies required to run **TACT** can be installed with the following command:

```bash
pip install -r requirements.txt
```


## üìä Datasets

The following table summarizes the benchmarks used in our experiments and provides their download links.

| **Dataset**    | **Link**                                                                                                                   |
| -------------- | -------------------------------------------------------------------------------------------------------------------------- |
| **SANTOS**     | [https://zenodo.org/record/7758091](https://zenodo.org/record/7758091)                                                     |
| **TUS**        | [https://github.com/RJMillerLab/table-union-search-benchmark](https://github.com/RJMillerLab/table-union-search-benchmark) |
| **Wiki Union** | [./data](./data)                                                                                                           |
| **WDC**        | [https://webdatacommons.org/webtables/](https://webdatacommons.org/webtables/)                                             |

For the **SANTOS**, **TUS**, and **WDC** benchmarks, we include links to their official sources for convenient access and reproducibility.
For the **Wiki Union** benchmark, which we constructed based on existing resources, we provide our version of the dataset in this repository to facilitate future research.
We also thank [**LakeBench**](https://zenodo.org/records/8014643) for providing the data and labels that served as the foundation for constructing the **Wiki Union** benchmark.


## üöÄ Run the Code

This section provides instructions for running **TACT**, including pretraining, inference, querying, and reranking.

1. Pretrain by running:

```bash
python pretrain.py --task [task] --logdir [dir_path] --save_model
```

2. Inference by running:

```bash
python extractVectors.py --benchmark [task] --save_model & python extractFasttext.py --task [task] & wait

```

3. Querying by running 

```bash
python query.py --benchmark [task] --K [top_k_value]
```

4. Reranking by running

```bash
python rerank.py --task [task]
```


## üôè Acknowledgement

We gratefully acknowledge the open-source implementation of [**Starmie**](https://github.com/megagonlabs/starmie), which provides basic components that facilitated parts of our implementation.
We also thank [**LakeBench**](https://zenodo.org/records/8014643) for providing the data and labels that served as the foundation for constructing the **Wiki Union** benchmark.